import os
import re
import pymupdf4llm
from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

pdf_data_path = "data"
vector_db_path = "vectorstores/db_faiss"

def clean_and_format_markdown(md_text):
    """
    HÃ m chuáº©n hÃ³a Markdown, Ä‘áº£m báº£o Splitter cáº¯t Ä‘Ãºng ChÆ°Æ¡ng/Äiá»u
    """
    # Regex nÃ y tÃ¬m cÃ¡c dÃ²ng báº¯t Ä‘áº§u báº±ng "Äiá»u" + sá»‘, vÃ  thÃªm "## " vÃ o trÆ°á»›c
    md_text = re.sub(r'\n(Äiá»u \d+)', r'\n## \1', md_text)
    # 2. ThÃªm dáº¥u # vÃ o trÆ°á»›c chá»¯ "ChÆ°Æ¡ng"
    md_text = re.sub(r'\n(ChÆ°Æ¡ng [IVX]+)', r'\n# \1', md_text)
    # 3. Xá»­ lÃ½ trÆ°á»ng há»£p in Ä‘áº­m sai: **Äiá»u 1** -> ## Äiá»u 1
    md_text = re.sub(r'\n\*\*(Äiá»u \d+.*?)\*\*', r'\n## \1', md_text)
    
    return md_text

def create_db_from_pdf_via_markdown():
    print("ğŸš€ Báº¯t Ä‘áº§u quy trÃ¬nh tá»± Ä‘á»™ng: PDF -> Markdown -> Vector DB...")
    
    all_splits = []
    
    if not os.path.exists(pdf_data_path):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c '{pdf_data_path}'")
        return

    # Duyá»‡t file vÃ  chuyá»ƒn Ä‘á»•i
    for filename in os.listdir(pdf_data_path):
        if filename.lower().endswith(".pdf"):
            file_path = os.path.join(pdf_data_path, filename)
            print(f"ğŸ“„ Äang xá»­ lÃ½: {filename}...")
            
            try:
                # PDF -> Markdown
                md_text = pymupdf4llm.to_markdown(file_path)
                
                # BÆ¯á»šC Tá»° Äá»˜NG Sá»¬A Lá»–I HEADER
                md_text = clean_and_format_markdown(md_text)
                
                # (TÃ¹y chá»n) LÆ°u file .md ra mÃ¡y Ä‘á»ƒ báº¡n kiá»ƒm tra
                # with open(f"{file_path}.md", "w", encoding="utf-8") as f:
                #     f.write(md_text)

                # Cáº¯t theo cáº¥u trÃºc vÄƒn báº£n hÃ nh chÃ­nh (Header)
                headers_to_split_on = [
                    ("#", "Header 1"),      # ChÆ°Æ¡ng
                    ("##", "Header 2"),     # Äiá»u
                    ("###", "Header 3"),    # Khoáº£n / Má»¥c lá»¥c nhá»
                ]
                
                markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)
                md_header_splits = markdown_splitter.split_text(md_text)
                
                # GÃ¡n metadata tÃªn file nguá»“n
                for split in md_header_splits:
                    split.metadata["source"] = filename
                
                all_splits.extend(md_header_splits)
                
            except Exception as e:
                print(f"âš ï¸ Lá»—i khi Ä‘á»c file {filename}: {e}")

    if not all_splits:
        print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u nÃ o Ä‘á»ƒ xá»­ lÃ½.")
        return

    print(f"âœ… ÄÃ£ tÃ¡ch sÆ¡ bá»™ thÃ nh {len(all_splits)} khá»‘i theo ChÆ°Æ¡ng/Äiá»u.")

    # 3. Cáº¯t nhá» tiáº¿p náº¿u má»™t "Äiá»u" quÃ¡ dÃ i (Ä‘á»ƒ vá»«a context cá»§a LLM)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1024,
        chunk_overlap=100
    )
    final_chunks = text_splitter.split_documents(all_splits)
    
    print(f"âœ‚ï¸ Tá»•ng sá»‘ chunks cuá»‘i cÃ¹ng: {len(final_chunks)}")

    # 4. Táº¡o Vector DB
    print("ğŸ§  Äang táº¡o Embeddings & lÆ°u vÃ o FAISS (bÆ°á»›c nÃ y máº¥t vÃ i phÃºt)...")
    embedding_model = HuggingFaceEmbeddings(model_name="bkai-foundation-models/vietnamese-bi-encoder")
    
    db = FAISS.from_documents(final_chunks, embedding=embedding_model)
    db.save_local(vector_db_path)
    print(f"ğŸ‰ Xong! Database Ä‘Ã£ lÆ°u táº¡i: {vector_db_path}")

if __name__ == "__main__":
    create_db_from_pdf_via_markdown()